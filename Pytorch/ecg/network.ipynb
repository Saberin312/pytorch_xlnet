{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bn_relu(layer, dropout=0, **params):\n",
    "    from keras.layers import BatchNormalization\n",
    "    from keras.layers import Activation\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation(params[\"conv_activation\"])(layer)\n",
    "\n",
    "    if dropout > 0:\n",
    "        from keras.layers import Dropout\n",
    "        layer = Dropout(params[\"conv_dropout\"])(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conv_weight(\n",
    "        layer,\n",
    "        filter_length,\n",
    "        num_filters,\n",
    "        subsample_length=1,\n",
    "        **params):\n",
    "    from keras.layers import Conv1D \n",
    "    layer = Conv1D(0\n",
    "        filters=num_filters,\n",
    "        kernel_size=filter_length,\n",
    "        strides=subsample_length,\n",
    "        padding='same',\n",
    "        kernel_initializer=params[\"conv_init\"])(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conv_layers(layer, **params):\n",
    "    for subsample_length in params[\"conv_subsample_lengths\"]:\n",
    "        layer = add_conv_weight(\n",
    "                    layer,\n",
    "                    params[\"conv_filter_length\"],\n",
    "                    params[\"conv_num_filters_start\"],\n",
    "                    subsample_length=subsample_length,\n",
    "                    **params)\n",
    "        layer = _bn_relu(layer, **params)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(\n",
    "        layer,\n",
    "        num_filters,\n",
    "        subsample_length,\n",
    "        block_index,\n",
    "        **params):\n",
    "    from keras.layers import Add \n",
    "    from keras.layers import MaxPooling1D\n",
    "    from keras.layers.core import Lambda\n",
    "\n",
    "    def zeropad(x):\n",
    "        y = K.zeros_like(x)\n",
    "        return K.concatenate([x, y], axis=2)\n",
    "\n",
    "    def zeropad_output_shape(input_shape):\n",
    "        shape = list(input_shape)\n",
    "        assert len(shape) == 3\n",
    "        shape[2] *= 2\n",
    "        return tuple(shape)\n",
    "\n",
    "    shortcut = MaxPooling1D(pool_size=subsample_length)(layer)\n",
    "    zero_pad = (block_index % params[\"conv_increase_channels_at\"]) == 0 \\\n",
    "        and block_index > 0\n",
    "    if zero_pad is True:\n",
    "        shortcut = Lambda(zeropad, output_shape=zeropad_output_shape)(shortcut)\n",
    "\n",
    "    for i in range(params[\"conv_num_skip\"]):\n",
    "        if not (block_index == 0 and i == 0):\n",
    "            layer = _bn_relu(\n",
    "                layer,\n",
    "                dropout=params[\"conv_dropout\"] if i > 0 else 0,\n",
    "                **params)\n",
    "        layer = add_conv_weight(\n",
    "            layer,\n",
    "            params[\"conv_filter_length\"],\n",
    "            num_filters,\n",
    "            subsample_length if i == 0 else 1,\n",
    "            **params)\n",
    "    layer = Add()([shortcut, layer])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_filters_at_index(index, num_start_filters, **params):\n",
    "    return 2**int(index / params[\"conv_increase_channels_at\"]) \\\n",
    "        * num_start_filters\n",
    "\n",
    "def add_resnet_layers(layer, **params):\n",
    "    layer = add_conv_weight(\n",
    "        layer,\n",
    "        params[\"conv_filter_length\"],\n",
    "        params[\"conv_num_filters_start\"],\n",
    "        subsample_length=1,\n",
    "        **params)\n",
    "    layer = _bn_relu(layer, **params)\n",
    "    for index, subsample_length in enumerate(params[\"conv_subsample_lengths\"]):\n",
    "        num_filters = get_num_filters_at_index(\n",
    "            index, params[\"conv_num_filters_start\"], **params)\n",
    "        layer = resnet_block(\n",
    "            layer,\n",
    "            num_filters,\n",
    "            subsample_length,\n",
    "            index,\n",
    "            **params)\n",
    "    layer = _bn_relu(layer, **params)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_output_layer(layer, **params):\n",
    "    from keras.layers.core import Dense, Activation\n",
    "    from keras.layers.wrappers import TimeDistributed\n",
    "    layer = TimeDistributed(Dense(params[\"num_categories\"]))(layer)\n",
    "    return Activation('softmax')(layer)\n",
    "\n",
    "def add_compile(model, **params):\n",
    "    from keras.optimizers import Adam\n",
    "    optimizer = Adam(\n",
    "        lr=params[\"learning_rate\"],\n",
    "        clipnorm=params.get(\"clipnorm\", 1))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "def build_network(**params):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input\n",
    "    inputs = Input(shape=params['input_shape'],\n",
    "                   dtype='float32',\n",
    "                   name='inputs')\n",
    "\n",
    "    if params.get('is_regular_conv', False):\n",
    "        layer = add_conv_layers(inputs, **params)\n",
    "    else:\n",
    "        layer = add_resnet_layers(inputs, **params)\n",
    "\n",
    "    output = add_output_layer(layer, **params)\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    if params.get(\"compile\", True):\n",
    "        add_compile(model, **params)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
